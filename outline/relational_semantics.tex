% !TEX root = main.tex
In this section, we first recall the well-studied relational semantics of linear logic weighted over a continous semiring $\Rsemiring$, although in a slightly different flavor than the one used in (cite Laird, Manzonetto): rather than using $\Rsemiring$-valued matrices, we will use formal power series over $\Rsemiring$, as in (cite Paolo and Davide's work about tropical lambda calculus). Then, we focus on algebraic power series: this is a concept widely used in algebra and combinatorics (cite Flajolet, Kauers, Eisenbud), in the context of rings or fields. Its treatment in semi-rings is less standard, but extensively studied in the context of formal language theory (cite Kuich, Schlund). We will show that, through the relational semantics, such ideas apply naturally to the semantics of probabilistic $\lambda$-calculi.



%but we will not have to worry too much about this, as we will work with a semirings $\Rsemiring$ (usually $\Rinf$) that has a subsemiring embe\\

\subsection{Formal Power Series}
We recall some notions about formal power series; for more details about them and their applications to combinatorics we refer to (cite the concrete tetrahedron). Given a set $\Sigma$, 
let us call $!\Sigma$ the set of finite multisets over it, i.e functions $\mu: \Sigma \to \NAT$ with finite support. For a semiring $\Rsemiring$, we call $\fps{\Rsemiring}{\Sigma}$ the set of functions $!\Sigma \to \Rsemiring$. More concretely, if
 we introduce for each $s \in \Sigma$ a variable $x_s$ (we will denote by $x_\Sigma$ the set of all this variables), then a finite multiset $\mu \in !\Sigma$ can be seen as the monomial $x_\Sigma^\mu \bydef \Pi_{s \in \Sigma}x_s^{\mu(s)}$; then any formal power series $s\in \fps{\Rsemiring}{\Sigma}$ can be expressed as a formal sum:
 $$s=\sum_{\mu \in !\Sigma} s_\mu x_\Sigma^{\mu}.$$ 
 We will sometimes write $s(x_\Sigma)$ to underline which variables appear in $s$.
 For each $s\in \fps{\Rsemiring}{\Sigma}$, its \emph{support} $\supp~s\subseteq \ !\Sigma$ is the set of multisets $\mu$ such that $s_{\mu}\neq 0$. 

 
 In $\fps{\Rsemiring}{\Sigma}$ we can define two operations: sum, performed componentwise: $\sum_{\mu \in !\Sigma} r_\mu x_\Sigma^{\mu} + \sum_{\mu \in !\Sigma} s_\mu x_\Sigma^{\mu} \bydef \sum_{\mu \in !\Sigma} (r_\mu + s_\mu)  x_\Sigma^{\mu}$ and the Cauchy product: $$\sum_{\mu \in !\Sigma} r_\mu x_\Sigma^{\mu} \cdot \sum_{\mu \in !\Sigma} s_\mu x_\Sigma^{\mu} \bydef \sum_{\kappa \in !\Sigma} (\sum_{\mu + \nu = \kappa} r_\mu s_\nu))  x_\Sigma^{\kappa}.$$
 With these operations, $\fps{\Rsemiring}{\Sigma}$ is a semiring; if we take on it the pointwise partial order, it becomes a \emph{continuous} semiring: this means that all directed joins have a supremum, and such suprema commute with multiplication. Continuity is essential when we want to define the \textit{composition} of formal power series. Take a power series $r \in \fps{\Rsemiring}{\Sigma}$ and let $s_\Sigma\in \fps{\Rsemiring}{\Sigma'}^{\Sigma}$ be a $\Sigma$-indexed family of power series over the set $\Sigma'$, $s_\sigma = \sum_{\nu \in !\Sigma'}s_{\sigma, \nu} y^\nu$. Then, we can define the power series $r(s_\Sigma) \in \fps{\Rsemiring}{\Sigma'}$ by the formula:
 \begin{align*}
  &r(s_\Sigma) =\\ &\sum_{\kappa \in ! \Sigma'} y_\Sigma^\kappa \left( \sum_{[\sigma_1^{m_1} \dots \sigma_j^{m_j}] \in !\Sigma} r_{{[\sigma_1^{m_1} \dots \sigma_j^{m_j}] }} \sum_{\nu_1 + \dots + \nu_{m_1 + \dots + m_j}= \kappa} \prod_{i=1}^{m_1 + \dots + m_j} s_{\sigma_i, \nu_i } \right)
  \end{align*}
  Observe that the if there is at least an $s_\sigma$ such that $s_{\sigma, []} \neq 0$, the sum over $!\Sigma$ will be infinite; still, being in a continuous semiring, we can define its value to be the sup of the partial sums (yet, notice that, over a - non-continuous - ring, this composition would not be well-defined). If the power series $s_\Sigma$ are all constants (i.e. $s_{\sigma, \mu}=0 \: \forall \mu \neq []$), we will say that $r(s_\Sigma) \in \fps{\Rsemiring}{\emptyset}= \Rsemiring$ is the \emph{value of $r$ at the point} $(s_{\sigma, []})_{\sigma \in \Sigma}$.
  
  
Since $\Qsemiring:=\fps{\Rsemiring}{\Sigma}$ is a continuous semiring, for any set $\Sigma'$ we can consider the continuous semiring $\fps{\Qsemiring}{\Sigma'}$ of formal power series whose coefficients are themselves power series (on $\Rsemiring$), and we have the isomorphism $\fps{\Qsemiring}{\Sigma'}=\fps{(\fps{\Rsemiring}{\Sigma})}{\Sigma'}\equiv\fps{\Rsemiring}{\Sigma+\Sigma'}$: this generalizes the well-known remark that that a fps in two variables $s(x,y)$ can always be written as a fps $s_y(x)=\sum_n s_n(y)x^n$ in $x$ whose coefficients are fps $s_n(y)$ in $y$.
  
  For a finite set $\Sigma$ and a natural number $k$, let $!_k\Sigma$ be the set of multisets $\mu$ of maximal multeplicity $k$ (i.e $\max_{x \in \Sigma} \mu(x)\leq k)$. This is clearly a subset of $!\Sigma$, corresponding to monomials over $x_\Sigma$ having degree at most $n$ in each variable. If a power series $s\in \fps{ \Rsemiring}{\Sigma}$ is such that $\supp s \subseteq !_k \Sigma$, for some $k\in \N$, we say that $s$ is a \textit{generalized} polynomial;  if moreover $\supp s$ is finite we say that it is a \emph{classical} polynomial. All classical polynomials are generalized polynomials, but the converse is not true unless $\Sigma$ is finite. When we say `polynomial' without any specification, we always mean a classical polynomial.
  \begin{example}
  	$\sum_{n} (1/2)^n x^n$ belongs to $\fps{\Rinf}{x}$ and it is neither a generalized nor a classical polynomial, while  $\sum_{n \geq 1} (1/2)^n x_1 \dots x_n \in \fps{\Rinf}{x_\N}$ is a generalized polynomial but not a polynomial, and  $\sum_{1 \leq n \leq 50} (1/2)^n x_1 \dots x_n \in \fps{\Rinf}{x_\N}$ is a polynomial.
  \end{example}
   As usual, a classical polynomial $p$ can be written as a finite sum:
  $$p= \sum_{n_1 \dots n_{|\Sigma|} = 0}^k p_{n_1 \dots n_{|\Sigma|}} x_{\sigma_1}^{n_1} \dots x_{\sigma_{|\Sigma|}}^{n_{|\Sigma|}}$$
  Polynomials form a sub-semiring of $\fps{\Rsemiring}{\Sigma}$, that we will denote as $\fpp{\Rsemiring}{\Sigma}$. It is obviously not continuous, as the supremum of a collection of polynomials can be an infinite power series. Composition of polynomials do not involve infinite sums: the coefficients of the composition $r(s_\Sigma)$ are indeed polynomials in the coefficients of $r$ and $s_\Sigma$:
  \begin{lemma}
  	For each $\Sigma$ and $\Sigma'$ and for each $k \in \N$ and for each  $\Sigma$-indexed family of natural numbers $k_\Sigma$, there exists a $!\Sigma'$-indexed family $p_{\Sigma'}$ of polynomials over $!_k \Sigma \sqcup \left( \bigsqcup_{\sigma \in \Sigma} !_{k_\sigma}\Sigma'  \right)$ with the following property:
  	if $r \in \fpp{\Rsemiring}{\Sigma}$ and $s_\Sigma$ is a $\Sigma'$-indexed family of power series $\in  \fpp{\Rsemiring}{\Sigma'}$, then $\mu$ coefficient of $r(s_\Sigma) \in \fpp{\Rsemiring}{\Sigma'}$ is equal to:
  	$$p_{\mu}((r_\kappa)_{\kappa \in !_k\Sigma}, (s_{\sigma_1, \kappa})_{\kappa \in !_{k_1}\Sigma}  \dots (s_{\sigma_n, \kappa})_{\kappa \in !_{k_n}\Sigma}) $$
  \end{lemma}
  Let us say something on what happens if we do not start with a continuous semiring $\Rsemiring$, but rather with a ring $R$. In this case, almost all of the constructions we made  still work: we can similarly define the set $\fps{R}{\Sigma}$ of formal power series over $R$, which is a ring, as well as its subring  $\fps{R}{\Sigma}$ of polynomials over $R$. Still, the composition of formal power series will not be defined in general, as it involves an infinite sum, while the composition of polynomials remains well-defined.
  
  
  \subsection{The Weighted Relational Semantics}
  
    Now, we recall the link between formal power series and the weighted relational model of linear logic. In (cite Laird, Manzonetto), given a continous semiring $\Rsemiring$, a category $\Qrel{\Rsemiring}$ is defined, whose objects are sets, and morphisms $\Qrel{\Rsemiring}(X, Y)$ are $\Rsemiring$-valued matrices indexed by $X \times Y$. 
The coKleisli category $\Qrelkleisli{\Rsemiring}$, with respect to the $!$ comonad, has morphisms $\Qrelkleisli{\Rsemiring} (X, Y)$ given by $\Rsemiring$-valued matrices indexed by $!X \times Y$; since a matrix $(t_{\mu, y})_{\mu \in !X, y \in Y}$ can be seen as a $Y$-indexed family of power series $(\sum t_{\mu, y} x_X^\mu)_{y \in Y}$, the morphisms of $\Qrelkleisli{\Rsemiring}$ can be identified with (families of) formal power series, i.e.~$\Qrelkleisli{\Rsemiring}(X,Y)\equiv\fps{\Rsemiring}{X}^Y$.
    Indeed, composition in $\Qrelkleisli{\Rsemiring}$ is given by (pointwise) composition of the underlying power series, with identities $\mathrm{id}_X\in  \fps{\Rsemiring}{X}^X$ given by
    $(\mathrm{id}_X)_i(x_X)=x_i$.
%    
%     By this identification, we can from now one see $\Qrelkleisli{\Rsemiring}$ as a category whose objects are set and whose morphisms $\Qrelkleisli{\Rsemiring} (X, Y)$ are  $Y$-indexed family $s_Y$ of power series over $x_X$.\\

%The category $\Qrel{\Rsemiring}$ is symmetric monoidal closed, with monoidal products and their their adjoints both given by $X\times Y$, yielding an interpretation of the \emph{linear} $\lambda$-calculus.
$\Qrelkleisli{\Rsemiring}$ is cartesian closed, with cartesian products given by $X+Y$ (with neutral $0:=\emptyset$) and exponentials given by $!X\times Y$. The fundamental intuition about the exponential is that giving a $(!X\times Y)$-indexed family of fps $s_{\mu,y}(z_Z)\in \Qrelkleisli{\Rsemiring}(Z,!X\times Y)=\fps{\Rsemiring}{Z}^{!X\times Y}$ is the same as giving a $Y$-indexed family of fps $s(z_Z,x_{X})_y=\sum_{\mu\in !X}s_{\mu,y}(z_Z)x_X^{\mu}\in \Qrelkleisli{\Rsemiring}(Z+X,Y)\equiv \fps{\Rsemiring}{Z+X}^Y$.
This generalizes the correspondence between a fps $\sum_{\mu\in !X} s_{\mu}x^\mu$ and its family of coefficients $(s_\mu)_{\mu\in \ !X}$.
%The interpretation of a program $M:A\to B$ is a $\Rsemiring$-matrix $\model{M}^{\Rsemiring}\in\Rsemiring^{!A\times B}=\fps{\Rsemiring}{0}^{!A\times B}$ whose entries $ (\model{M}^{\Rsemiring})_{\mu,b}$ represent ways of yielding $b$ by using each input $a\in A$ exactly $\mu(a)$ times. 

\begin{example}\label{ex:churchtwo}
Consider the program $M=\lambda x.y(yx)$, where $y:(\1\to\1)\vdash M:\1\to\1$: letting $\model{\1}=1=\{\star\}$, and 
observing that $!\1\times \1\equiv \N$, 
we have that $M$ is interpreted by a $\N$-indexed family of power series
$s(y_{\N})_i\in \Qrelkleisli{\Rsemiring}(\N,\N)=\fps{\Rsemiring}{\N}^{\N}$.
%, corresponding to the fps $\sum_{i=0}^{\infty}s(y_{\N})_i x^i$. 
Now, think of the variables $y_{\N}$, which interpret the function $y:\1\to\1$, as encoding the fps $a(x)=\sum_n y_n x^n\in\Qrelkleisli{\fps{\Rsemiring}{\N}}(\1,\1)\equiv  \fps{(\fps{\Rsemiring}{\N})}{1}$;
the term $M$ should translate then into the composition $a(a(x))=\sum_n y_n\left(\sum_m y_mx^m\right)^n=\sum_{i=0}^{\infty}s(y_{\N})_ix^i$, which gives
\begin{align*}
s(y_{\N})_i&= \sum_{{\tiny\begin{matrix}(n,m_1,\dots, m_n),\\ m_1+\dots+m_n=i\end{matrix}}}y_ny_{m_1}\dots y_{m_n}.
%x^i=t(y_{\N})_i.
%\sum_{{\tiny\begin{matrix}(n,m_1,\dots, m_n),\\ m_1+\dots+m_n=i\end{matrix}}}y_n(y_{m_1}x^{m_1})\dots( y_{m_n}x^{m_n})\\
%&=
% \sum_{{\tiny\begin{matrix}(n,m_1,\dots, m_n),\\ m_1+\dots+m_n=i\end{matrix}}}y_ny_{m_1}\dots y_{m_n}x^i=t(y_{\N})_ix^i.
\end{align*}
Notice that the evaluation $y:(\1\to\1),x:\1\vdash Mx:\1$ is precisely interpreted by $a(a(x))\in \Qrelkleisli{\Rsemiring}(\N+1,1)=\fps{\Rsemiring}{\N+1}\equiv\fps{(\fps{\Rsemiring}{\N})}{1}$.

%In other words, since $\fps{\Rsemiring}{\N+1}\equiv\fps{\fps{\Rsemiring}{\N}}{\1}$, 
%we can look at $s(y_{\N},x)$ as a power series in $x$ whose $i$-th coefficient is the fps $t(y_{\N})_i=  \sum_{{\tiny\begin{matrix}(n,m_1,\dots, m_n),\\ m_1+\dots+m_n=i\end{matrix}}}y_ny_{m_1}\dots y_{m_n}\in \fps{\Rsemiring}{y_{\N}}$.
%
%
%
%The program $y:(\1\to \1),x:\1\vdash Mx:\1$ is then interpreted by a single power series
%$t(y_{\N},x)\in \Qrelkleisli{\Rsemiring}(\N+1,1)=\fps{\Rsemiring}{\N+1}$ given by
%\[
%t(y_{\N},x)_i=s(y_{\N})_ix^i= 
%\sum_{{\tiny\begin{matrix}(n,m_1,\dots, m_n),\\ m_1+\dots+m_n=i\end{matrix}}}y_n(y_{m_1}x^{m_1})\dots( y_{m_n}x^{m_n}).
%\]
%In other words, the fps $s(y_{\N})_{i}$ is the coefficient of the map $\1\to \1$ corresponding to 
\end{example}

%The example above shows that the usual evaluation map $\Qrelkleisli{\Rsemiring}(Z,!X\times Y)\Rightarrow \Qrelkleisli{\Rsemiring}(Z+X, Y)$, i.e.~
%$\fps{\Rsemiring}{Z}^{!X\times Y}\To\fps{\Rsemiring}{Z+X}^Y$, corresponds to passing from the $!X\times Y$-indexed family of power series 
%$s(z_Z)_{\mu,y}\in \fps{\Rsemiring}{Z}$ to the $Y$-indexed family
%$t(z_Z,x_X)_y=\sum_{\mu\in !X}s(z_Z)_{\mu,y}x_X^\mu\in \fps{\Rsemiring}{Z+X}$.
%When $Z=0$, this precisely corresponds to passing from a $!X\times Y$-indexed family of scalars
%$s_{\mu,y}$ to the corresponding $Y$-indexed family of power series $\sum_{\mu\in !X}s_{\mu,y}x_X^\mu$. 
%

%
%Notice that usual curryfication $\Qrelkleisli{\Rsemiring}(X,Y)\Rightarrow \Qrelkleisli{\Rsemiring}(1,!X\times Y)$ corresponds to passing from 
%
%For instance, an arrow $s(x_{\star})\in \Qrelkleisli{\Rsemiring}(\1,\1)\equiv\fps{\Rsemiring}{x_{\star}}\equiv \ !\1\to \Rsemiring\equiv\N\to\Rsemiring$ is a power series
%$s_{x_{\star}}=\sum_n s_nx_{\star}^n$.



Beyond exponentials, 
$\Qrelkleisli{\Rsemiring}$ has all (contextual) fixpoints (cite ?? and maybe refine terminology): given a morphism $f \in \Qrelkleisli{\Rsemiring}(X + Y, X)$.  we can define its fixpoint $\fix f \in \Qrelkleisli{\Rsemiring}(Y, X)$ as follows: take the sequence $f_0 \bydef  0 \times id_Y \in \Qrelkleisli{\Rsemiring}(1 \times Y ,X \times Y), \: f_{n+1} \bydef f \circ (f_n \times id_Y) \circ \langle id_\1, \Delta_Y \rangle  \in \Qrelkleisli{\Rsemiring}(1 \times Y, X)$ and finally let $\fix f \bydef \sup_n f_n \in \Qrelkleisli{\Rsemiring}( Y, X)$.
   It is worth to restate this construction in terms of power series: $f$ will be represented by an $X$-indexed family $(s_x(x_X, x_Y))_{x \in X}$. Then we can define its iterates and the fixpoint as follows, for $x \in X$:
   \begin{align*}
   	& r_x^{(0)}(x_Y) = 0 \in \fps{\Rsemiring}{Y}\\
   	& r^{(n+1)}_x(x_Y) =  s_x(r_X(x_Y), x_Y)\\
   	& (\fix s_X)_x(x_Y) = \sup_n r^{(n)}_x(x_Y)
   \end{align*} 
	From this, it is clear that the power series $r_X= \fix f$ are the minimal solution of the infinite family of equations: $(r_x = s_x(r_x, x_Y))_{x \in X}$. 
	

Probabilistic choice can be interpreted in $\Qrelkleisli{\Rsemiring}$ for suitable choices of $\Rsemiring$. First, in all $\Qrelkleisli{\Rsemiring}$ it is possible to interpret \emph{weighted choices} $w_0\cdot M+w_1\cdot N$, where $w_0,w_1\in \Rsemiring$, by letting
  $\model{w_0\cdot M+w_1\cdot N}=w_0\model{M}+w_1\model{N}$.
%  
% 
%  are interpreted s the sum of the corresponding fps; 
% 
% moreover, we can interpret \emph{weigted terms} $w\times M$ (as in the language $PCF^{\Rsemiring}$ of Laird, Manzonetto); its interpretation is naturally given by $\model{w\cdot M}^{\Rsemiring}=w\model{M}^{\Rsemiring}$.  
%
Now, if $\Rsemiring$ contains $\Rinf$ as a sub-semiring, we can interpret a choice $M\oplus_p N$ with bias $p\in [0,1]$ as the weighted choice $p\cdot M + (1-p)\cdot N$; 
taking instead $\Qsemiring=\fps{\Rsemiring}{x,\overline x}$, it is even possible to interpret 
\emph{parametric} choices $M\oplus_x N$, i.e.~choices according to some unknown bias $x$, by rewriting them as $x\cdot M+\overline{x}\cdot N$ (see Barbarossa and Pistone).
 
% $\Qrelkleisli{\Rsemiring}$ has thus all the relevant structure to define an interpretation $\model{-}^{\Rsemiring}$ of higher-order languages with fixpoints, like the $\lambda Y$ calculus or PCF (see Laird Manzonetto for all details).

%
%For suitable semirings, \emph{probabilistic choices} can be interpreted via non-determinism and weights: if $\Rsemiring$ contains $\Rinf$ as a sub-semiring, we can interpret a choice $M\oplus_p N$ with bias $p\in [0,1]$ by rewriting it as $p\cdot M + (1-p)\cdot N$; 
%taking instead $\Qsemiring=\fps{\Rsemiring}{x,\overline x}$, it is even possible to interpret 
%\emph{parametric} choices $M\oplus_x N$, i.e.~choices according to some unknown bias $x$, by rewriting it as $x\cdot M+\overline{x}\cdot N$ (see Barbarossa and Pistone).

Hence, one can interpret $\lambda_{\oplus} Y$ (or even probabilistic PCF) in all $\Qrelkleisli{\Rsemiring}$ with $\Rsemiring$ of the form $\fps{\Rinf}{\Sigma}$. When $\Rsemiring=\Rinf$, the interpretation precisely captures the call-by-value probabilistic execution of closed terms, as stated below: 
%the interpretation $\model{M}^{\Rinf}$ of a term $M:\1$ of ground type consists in a real number, since $\model{M}^{\Rinf}\in\Qrelkleisli{\Rsemiring}(0,\1)\equiv\fps{\Rsemiring}{0}\equiv\Rsemiring$, which coincides with the probability of termination of $M$, computed as the sum of the weights $w(R)\in \Rinf$ of all call-by-name probabilistic reductions $R:M{\to^*}e$:
\begin{proposition}[cite Pagani and co]
For any $\lambda_{\oplus} Y$ closed term $M:\1$, 
\begin{equation}\label{eq:prob1}
\model{M}^{\Rinf}=\mathbf P(M\Downarrow)=\sum_{R:M\to^* e}w(R).
\end{equation}
\end{proposition}
\begin{remark}
That $\model{M}^{\Rinf}$ precisely counts the probability of termination by summing the weights of all reductions is best seen from the parametric interpretation $\model{M}^{\Rsemiring}$, with $\Rsemiring=\fps{\Rinf}{x,\overline x}$, of (Barbarossa, Pistone) recalled above: in that case 
$\model{M}^{\Rsemiring}$ is a power series of the form
\begin{equation}\label{eq:prob2}
\model{M}^{\Rsemiring}(x,\overline x)=\sum_{m,n}\sharp(m,n)x^m {\overline x}^n,
\end{equation}
where $\sharp(m,n)\in \N$ is the number of reductions $R:M\to^* e$ making $m$ left choices and $n$ right choices. One recovers \eqref{eq:prob1} by \emph{evaluating} the power series \eqref{eq:prob2} over the actual biases $x:=p, \overline x:=1-p$. 
\end{remark}


A useful property is that all closed first-order terms of $\Lambda_{\oplus} Y$ are \emph{affine}, as stated below:
\begin{proposition}\label{prop:affine}
For all first-order terms $x_1:\1,\dots, x_n:\1\vdash_{\Lambda_{\oplus} Y}M:\1$, 
$\model{M}^{\Rinf}(x_1,\dots, x_n)\in \fps{\Rinf}{x_1,\dots,x_n}$ is affine: there exists scalars $w_0,w_1,\dots, w_n\in\mathbb R_{\geq 0}$ such that
\[
\model{M}^{\Rsemiring}(x_1,\dots, x_n)
=w_0+w_1x_1+\dots+w_nx_n,
\]
where $w_0=\mathbf P[M\to^* e]$ and
$w_{i+1}=\mathbf P[M\to^* x_{i+1}]$.
 \end{proposition}
 
This result translates the fact that in a reduction of $M$ to normal form, a ground variable $x:\1$ can occur in head position \emph{at most once}: indeed, as soon as $x$ occurs in head position, we must have $M\to^* x$, that is, the reduction has terminated.




%\begin{example}\label{ex:churchtwo2}
%Proposition \ref{prop:affine} drastically simplifies the computation of 
%
%\end{example}

\begin{example}
Consider the order-1 PHORS defined by
\begin{align*}
Fx&= F(Fx)\oplus_{\frac{1}{2}} x,\\
S&= Fe.
\end{align*}
Its encoding in $\Lambda Y$ is given by $M=Y \lambda\langle F,S\rangle. M':(\1\to \1)\times \1$, where 
$M'=
\langle \lambda  x.F(Fx)\oplus_{\frac{1}{2}} x, Fe\rangle$. 
%
% Its interpretation $\model{M}^{\Rinf}\in 
% \Qrelkleisli{\Rinf}(1, \N+1)\equiv
% (\Rinf)^{\N +1}\equiv (\Rinf)^{\N}\times \Rinf$ (using $\model{\1\to \1}=\ !1\times 1\equiv\N$) is given by a pair $(f,s)$, where $f:\N \to \Rinf$ and $s\in \Rinf$.%
The interpretation $\model{\lambda \langle F,S\rangle.M'}^{\Rinf}$ 
 of $\lambda \langle F,S\rangle.M'=((\1\to \1)\times 1)\to (\1\to \1)\times 1$ is a $(\N+1)$-indexed family of power series
$t(y_{\N},x)_i\in \fps{\Rinf}{\N +1}$, given, for $i\in \N$, and recalling $s(y_{\N})_i$ from Example \ref{ex:churchtwo}, by
\[
t(y_{\N},x)_i=
\begin{cases}
\frac{1}{2}s(y_{\N})_1+\frac{1}{2}=\frac{1}{2}(
y_1^2+1)
& \text{ if }i=1,\\
\frac{1}{2}s(y_{\N})_i 
&\text{ if }i\in\N, i\neq 1,\\
\sum_{n}y_n&\text{ if }i=\star.
\end{cases}
\]
 
The interpretation $\model{M}^{\Rinf}$ is then given by the fixpoint of the family $t_{\N+1}$, i.e.~by the minimal solution $\mathsf{fix}\  s_{\N +1}$ of the family of equations
$(\mathsf{fix}\  s_{\N +1})_i=t((\mathsf{fix}\  s_{\N +1})_{\N +1})$. In the next section we will show that this is given by
\[
(\mathsf{fix}\  s_{\N +1})_i
=
\begin{cases}
1
& \text{ if }i=1,\star,\\
0&\text{ if }i\in\N, i\neq 1.
\end{cases}
\]
The sequence $\model{\pi_1M}^{\Rinf}=(\mathsf{fix}\  s_{\N +1})_{\N}$ interprets the first-order term $\pi_1M:\1\to \1$ (equivalently, the non-terminal $F:\1\to \1$, cf.~ADD REMARK) via the affine map $\sum_{i=0}^{\infty} (\mathsf{fix}\  s_{\N +1})_i x^i = x$; using Proposition \ref{prop:affine}, this translates into the fact that $\mathbf{P}(Fx\to^* x)=1$; 
the scalar $\model{\pi_2M}^{\Rinf}=(\mathsf{fix}\  s_{\N +1})_\star=1$ interprets the
 non-terminal $S$, and translates into $\mathbf P(S\to^* e)=1$.

\end{example}

%  Observe that, if $X=!X_1 \times X_2$ is an exponential object,
%  for all $f\in \Qrelkleisli{\Rsemiring}(Y,X)$, the usual evaluation arrow 
%  $
%%  Eval \circ f \times id_{Y_2}: 
%  Y \times Y_1 \to Y_2$ is represented by the family of series $(\sum_{\kappa \in !Y_1} (\sum t_{\mu, (\kappa, y_2)} x_X^\mu) x_{Y_1}^\kappa)_{y_2 \in Y_2}$\\
%  
  
  
  
  \section{Algebraic Power Series}
    We will now discuss how fixpoints in $\Qrelkleisli{\Rsemiring}$ are related to fixpoint algebraic systems. Suppose we have a morphism $f \in \Qrelkleisli{\Rsemiring}(X \times Y, X)$. Now, we can define as follows its fixpoint $\fix f \in \Qrelkleisli{\Rsemiring}(Y, X)$. Take the succession:$f_0 \bydef  0 \times id_Y \in \Qrelkleisli{\Rsemiring}(1 \times Y ,X \times Y), \: f_{n+1} \bydef f \circ (f_n \times id_Y) \circ \langle id_\1, \Delta_Y \rangle  \in \Qrelkleisli{\Rsemiring}(1 \times Y, X)$ and finally $\fix f \bydef \sup_n f_n \in \Qrelkleisli{\Rsemiring}(1 \times Y \simeq Y, X)$.
	We are interested to the case in which the fixpoint $r_\Sigma$ ha finite support, so that family can be reduced to a fixpoint algebraic system: asking just that the $s_x$ are polynomials is not enough , as there would be anyway infinitely many equations. 

  
  As we saw, power series are infinitary objects and their manipulation can then involve the concept of limit, making it generally uncomputable. Moreover, the continuous semiring we will generally use in the context of probabilistic semantics will be $\Rinf$ and the semiring of formal power series over $\Rinf$: hence, the computation with the coefficients of power series themselves could be infinitary. To our rescue, we will use a way to give a finitary specification of power series: this will be the concept of algebraicity. First, we recall it in the context of rings, which is the one most customary in combinatorics; we will then remark how the situation differs on a semiring :
  \begin{definition}
  	Let $R$ be a ring  and let $R'$ be a sub ring of it.
  	We say that a family $(s_1, \dots s_n)$ of formal power series $s_i \in \fps{R}{\Sigma}$ is an \textbf{algebraic family} over $R'$ if there exist polynomials $p(w_1, \dots w_n, x_\Sigma) \in \fpp{R'}{w_1, \dots w_n, \Sigma}$ such that:
  	\begin{equation*}
  	\begin{cases}
  		p_1(s_1, \dots s_n, x_\Sigma)=0\\
  		\dots\\
  		p_n(s_1, \dots s_n, x_\Sigma)=0\\
  	\end{cases}
  	\end{equation*}
  	 If for an $s \in \fps{R}{\Sigma}$, $(s)$ is an algebraic family (i.e there exists a polynomial $p(w_1, x_\Sigma) \in \fpp{R'}{w \cup \Sigma}$ such that $p(s, x_\Sigma)=0$, we say that $s$ is algebraic.
  \end{definition}
  \begin{example}
  	\begin{itemize}
  		\item Let $s \in \fps{\R}{x}$ be $\sum_{n \geq 0}x^n$. Then if we take the polynomial $p(w,x) = w(1-x)-1$, we get $p(s, x)=0$. Hence, $s$ is algebraic over $\Q$. Indeed, $s$ is the multiplicative inverse $(1-x)^{-1}$ of $(1-x)$ in $\fps{\R}{x}$. In general, every $\Q$ rational power series (i.e every power series of the form $r_1(x_\Sigma)r_2(x_\Sigma)^{-1}$ for $r_1, r_2 \in \fps{\Q}{\Sigma}$) is algebraic over $\Q$ 
  		\item Let $s= \sum_{n \geq 0} \frac{1}{n+1} \binom{2n}{n} x^{n} \in \fps{\R}{x}$. One can verify that this is the Taylor expansion around $0$ of the (analytic) function $\frac{1-\sqrt{1-4z}}{2z}$. From this, it is easy to see that, taking $p(w, x)= zw^2 - w + 1$, that $p(s, x)=0$. Observe that computing $s(1) = \sum_{n \geq 0} \frac{1}{n+1} \binom{2n}{n}$ as a limit is hard, but, using the equation $p(s(x), x)=0$, we can easily deduce that $s(1)$ is the (only) positive root of $w^2-w+1$. 
  		\end{itemize}
  \end{example}	
  We will now show that being for a power series $s$ over a ring which is an integrity domain being algebraic and being part of an algebraic familiy are the same:
  \begin{lemma}
  	(Here, it is necessary for R to be an UFD)
  	If $p, q \in \fpp{R'}{w_1,x_\Sigma}$, there exists a polynomial $Res_{w_1}(p,q) \in \fpp{R'}{x_\Sigma}$ such that if $(\bar w, \bar x_\Sigma)$  is a common root of $p,q$ in any extension $R \supseteq R'$, then $Res(\bar x_\Sigma)=0$.
  \end{lemma}
  \begin{lemma}
  	If $(s_1, \dots s_n)$ are an $R'$ algebraic family of power series, then each $s_i$ is an algebraic power series
  \end{lemma}
  \begin{proof}
  	Taking the resultant  $Res_i$ of $p_1$ with every $p_i \: i \geq 2$, we obtain a system of $n-1$ equations in the variables $w_2, \dots w_n, x_\Sigma$. Iterating this procedure $n-1$ times, we are left with a single equations in the variables $w_n, x_\Sigma$
  \end{proof}
  \begin{remark}
  \end{remark}
  The theory of algebraic power series should be stated in a slightly different way in the context of semirings: if $a \in \fps{\Rsemiring}{\Sigma}, a > 0$, then for each $k$ $a^k > 0$, hence it is not possible that $p(a, x_\Sigma)=0$ for some $p \in \fpp{\Rsemiring}{\Sigma}$. One could give the following definitions:
   \begin{definition}
  	Let $\Rsemiring$ be a semiring and let $\Rsemiring'$ be a subsemiring of it. Then
  	  	e say that a family $(s_1, \dots s_n)$ of formal power series $s_i \in \fps{\Rsemiring}{\Sigma}$ is an \textbf{algebraic family} over $\Rsemiring'$ if there exist polynomials $p(w_1, \dots w_n, x_\Sigma), q(w_1, \dots w_n, x_\Sigma)  \in \fpp{p(w_1, \dots w_n, x_\Sigma)'}{w_1, \dots w_n, \Sigma}$ such that:
  	\begin{equation*}
  		\begin{cases}
  			q_1(s_1, \dots s_n, x_\Sigma) = p_1(s_1, \dots s_n, x_\Sigma)\\
  			\dots\\
  			q_n(s_1, \dots s_n, x_\Sigma) = p_n(s_1, \dots s_n, x_\Sigma)\\
  		\end{cases}
  	\end{equation*}
  	If $q_i = w_i$ for each $i$ we say that $(s_1, \dots s_n)$ is a \textbf{fixpoint algebraic family} over $\Rsemiring'$ with parameters $x_\Sigma$ and that:
  		\begin{equation}
  		\label{fixpointsystem}
  		\begin{cases}
  			w_1 = p_1(s_1, \dots s_n, x_\Sigma)\\
  			\dots\\
  			w_n = p_n(s_1, \dots s_n, x_\Sigma)\\
  		\end{cases}
  	\end{equation}
  		is a  \textbf{fixpoint algebraic system over} $\Rsemiring'$ with parameters $x_\Sigma$. 
\end{definition}
	The theory of systems like \ref{fixpointsystem} has been extensively studied (cite Kuich, Schlund) in the context of formal language theory: in particular, it can be shown that they admit a minimal solution, that can be obtained by iterating the polynomials $p_1 \dots p_n$. We will not go into the details, because in the following we will be in general be interested into $\Rinf$ power series algebraic over $\Q_{\geq 0}$: in this case, the polynomial equations $w_i= p_i, \: p \in \fpp{\Qpos}{\Sigma}$ can be rewritten as $p'_i \bydef p_i- w_i = 0, \: p \in \fpp{\Qpos}{\Sigma}$. Rather than speaking of the minimal solution of \ref{fixpointsystem} as a system with coefficients in $\Qpos$, we will be able to speak about the minimal non negative solution of the system $(p'_i=0)_{1 \leq i \leq n}$ with coefficients over $\mathbb{Q}$.\\
%  Now, we recall the link between formal power series and the weighted relational model of linear logic. In (cite Laird, Manzonetto), given a continous semiring a category $\Qrel$ is defined, whose objects are sets and morphisms $\Qrel(X, Y)$ are $\Rsemiring$-valued matrices indexed by $X \times Y$. In the category $\Qrelkleisli{\Rsemiring}$, the coKleisli category of $\Qrel$ with respect to the $!$ comonad, morphisms $\Qrelkleisli{\Rsemiring} (X, Y)$ are $\Rsemiring$-valued matrices indexed by $!X \times Y$; as remarked in (cite Paolo and Davide), a matrix $(t_{\mu, y})_{\mu \in !X, y \in Y}$ can be seen as a $Y$-indexed family of power series $(\sum t_{\mu, y} x_X^\mu)_{y \in Y}$. By this identification, we can from now one see $\Qrelkleisli{\Rsemiring}$ as a category whose objects are set and whose morphisms $\Qrelkleisli{\Rsemiring} (X, Y)$ are  $Y$-indexed family $s_Y$ of power series over $x_X$.\\
%  Observe that if $Y$ is an exponential object $!Y_1 \times Y_2$, then the arrow $Eval \circ f \times id_{Y_2}: X \times Y_2 \to Y_1$ is represented by the family of series $(\sum_{\kappa \in !Y_1} (\sum t_{\mu, (\kappa, y_2)} x_X^\mu) x_{Y_1}^\kappa)_{y_2 \in Y_2}$\\
%  We will now discuss how fixpoints in $\Qrelkleisli{\Rsemiring}$ are related to fixpoint algebraic systems. Suppose we have a morphism $f \in \Qrelkleisli{\Rsemiring}(X \times Y, X)$. Now, we can define as follows its fixpoint $\fix f \in \Qrelkleisli{\Rsemiring}(Y, X)$. Take the succession:$f_0 \bydef  0 \times id_Y \in \Qrelkleisli{\Rsemiring}(1 \times Y ,X \times Y), \: f_{n+1} \bydef f \circ (f_n \times id_Y) \circ \langle id_\1, \Delta_Y \rangle  \in \Qrelkleisli{\Rsemiring}(1 \times Y, X)$ and finally $\fix f \bydef \sup_n f_n \in \Qrelkleisli{\Rsemiring}(1 \times Y \simeq Y, X)$.
   In terms of power series, $f$ will be represented by an $X$-indexed family $(s_x(x_X, x_Y))_{x \in X}$. Then we can define its iterates and the fixpoint as follows, for $x \in X$:
   \begin{align*}
   	& r_x^{(0)}(x_Y) = 0 \in \fps{\Rsemiring}{Y}\\
   	& r^{(n+1)}_x(x_Y) =  s_x(r_\Sigma(x_Y), x_Y)\\
   	& (\fix s_X)_x(x_Y) = \sup_n r^{(n)}_x(x_Y)
   \end{align*} 
	From this, it is clear that the power series $r_\Sigma= \fix f$ are the minimal solution of the infinite family of equations: $(r_x = s_x(r_x, x_Y))_{x \in X}$. 
	We are interested to the case in which the fixpoint $r_\Sigma$ ha finite support, so that family can be reduced to a fixpoint algebraic system: asking just that the $s_x$ are polynomials is not enough , as there would be anyway infinitely many equations. 
	\begin{definition}
		If $X' \subset X$, we define $I(s_X, X')$ to be the set:
		$$\{s_\sigma : s_\sigma(0) \neq 0 \lor s_\sigma \in \fpp{\Rsemiring}{X'} \sqcup Y \} $$
		Take an $X$-indexed family  of polynomials $(s_x(x_X, x_Y))_{x \in X}$. If there exist an $X' \subseteq X$ such that $I(s_X, X')$ is finite and $I(s_X, X') \subseteq X'$, we say $(s_x(x_X, x_Y))_{x \in X}$ is a finitary family.
	\end{definition}
	\begin{proposition}
		 Let $\Rsemiring'$ be a subsemiring of $\Rsemiring$.  
		 If $(s_x(x_X, x_Y))_{x \in X}$ is a finitary family of $\Rsemiring'$ polynomials, then $\fix s_X$ has finite support and it is the minimal solution of a fixpoint algebraic family over $\Rsemiring'$ .  
   \end{proposition}
   \begin{proof}(Sketch)
   		For each $X'$ such that $I(s_\Sigma, X') \subseteq X'$ , the support of $\fix s_X$ is contained in $I(s_\Sigma, X')$. Now, let $A \bydef I(s_\Sigma, X')$. Take the system of equations: $(r_a = s_a(r_a, x_Y))_{a \in A}$ and let $\bar r_A$ be one of its solution. Then, define $(t_x)_{x \in X}$ to be $r_x$ if $x \in A$ and $0$ otherwise. For each $x \not \in A$, $s_x$ does not contain any constant neither any variable $x_A, x_Y$: hence it satisfies $s_x(t_X, x_Y)=0$.
   \end{proof}
   Now assume that $X$ is an exponential objects, so that $\fix s_X$ can be interpreted as a function $X_1 \to X_2$, i.e as a family of power series $\sum_{\kappa \in !X} r_{\kappa, x_2} x_{X_1}^\kappa \in \fpp{\Rsemiring}{X_1}$.
   	\begin{corollary}
   	In the setting of the previous proposition, if $X$ is an exponential object $X_1 \to X_2$ and 
   	$\Rsemiring' = \mathbb{Q}^+$, $\Rsemiring = \Rinf$, we have that for all $x_2 \in X_2$, the power series $\sum_{\kappa \in !X} r_{\kappa, x_2} x_{X_1}^\kappa \in \fpp{\R}{X_1}$ is algebraic over $\R$ with parameters $x_Y$.
   \end{corollary}
 